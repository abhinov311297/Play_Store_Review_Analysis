{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinov311297/Play_Store_Review_Analysis/blob/main/Seoul_Bike_Sharing_Team_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression \n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -** Abhinov Anand\n",
        "##### **Team Member 2 -** Vivek Kumar\n",
        "##### **Team Member 3 -** Saurav Kumar\n"
      ],
      "metadata": {
        "id": "W6ess-Diz8mV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **SEOUL BIKE SHARING DEMAND PREDECTION**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes. Data Description The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information. Attribute Information"
      ],
      "metadata": {
        "id": "XgKmr0fxx-UV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variables\n",
        "\n",
        "**Date** : year-month-day\n",
        "\n",
        "**Rented Bike count** - Count of bikes rented at each hour\n",
        "\n",
        "**Hour** - Hour of he day\n",
        "\n",
        "**Temperature**-Temperature in Celsius\n",
        "\n",
        "**Humidity**- %\n",
        "\n",
        "**Windspeed** - m/s\n",
        "\n",
        "**Visibility** - 10m\n",
        "\n",
        "**Dew point temperature** - Celsius\n",
        "\n",
        "**Solar radiation** - MJ/m2\n",
        "\n",
        "**Rainfall** - mm\n",
        "\n",
        "**Snowfall** - cm\n",
        "\n",
        "**Seasons** - Winter, Spring, Summer, Autumn"
      ],
      "metadata": {
        "id": "F6PBCcWkyM-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INTRODUCTION**"
      ],
      "metadata": {
        "id": "a06BHOK0ZJlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the problem related to the regression prediction where we have to predict continuous target variable that is rented bike sales using the different independent variables related to the atmospheric condition.\n",
        "\n",
        "Here we ll follow few norms for systemizing the approach to find the best prediction.\n",
        "\n",
        "1-Data Exploration and analysing pattern of relation among different variables.\n",
        "\n",
        "2-Removing outliers and dropping correlating variables.\n",
        "\n",
        "3-Defining target variables and features variables\n",
        "\n",
        "4-Splitting the data for training and testing.\n",
        "\n",
        "5-Choosing the different model like linear regression,random forest regression,polynomial regression.\n",
        "\n",
        "6-Fitting the data and predicting result\n",
        "\n",
        "7-Evaluation of the result using different metrics like Mean Squared Error,R2_score etc.\n",
        "\n",
        "8-HyperParameterTuning using Lasso,Ridge,Grid Search CV\n",
        "\n",
        "9-Comparing different model with the help of metrics.\n",
        "\n",
        "10-Analysing importance of different features in prediction(Model Explainability).\n",
        "11-Conclusion"
      ],
      "metadata": {
        "id": "-uOv3RWQ0TOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the file."
      ],
      "metadata": {
        "id": "Zd071uVV6bCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path ='/content/drive/MyDrive/CAPSTONE_PROJECT-2/'"
      ],
      "metadata": {
        "id": "KMH6AxupWisH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(path+'SeoulBikeData.csv',encoding='unicode_escape') #Reading Dataset"
      ],
      "metadata": {
        "id": "4lmE4xtRW8wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of row=8760\n",
        "\n",
        "Number of columns=14"
      ],
      "metadata": {
        "id": "9QGfKxZG6kHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(df[df.duplicated()])\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Duplicate Values."
      ],
      "metadata": {
        "id": "NUJV-iXf65RF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Missing Values."
      ],
      "metadata": {
        "id": "PeSK2dRm7E1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "BBq-HCSs-NDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking at the mean,max,stadard it looks like it might contain many outliers."
      ],
      "metadata": {
        "id": "p-OBq8vaDLLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependent variable 'Rented Bike Count\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.distplot(df['Rented Bike Count'],color='r')"
      ],
      "metadata": {
        "id": "P2YEoBzwQa73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After plotting the Density plot of number of rented bike,we can see that majority is in between 100 to 1200 rented bikes with an outliers upto 3500.\n",
        "\n",
        "The density plot is positively skewed thus needs transformation for normalising the distribution of data."
      ],
      "metadata": {
        "id": "LrOrzAH9Eq7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#skewness and kurtosis\n",
        "print(\"Skewness: %f\" % df['Rented Bike Count'].skew())\n",
        "print(\"Kurtosis: %f\" % df['Rented Bike Count'].kurt())"
      ],
      "metadata": {
        "id": "SOfDmgAlvYj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here skewness is 1.168 while the kurtosis is 0.862."
      ],
      "metadata": {
        "id": "By4KzuC9Gb68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reducing Skewness by root squaring target variables.\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.distplot(np.sqrt(df['Rented Bike Count']),color='r')"
      ],
      "metadata": {
        "id": "66SXWqwmJkgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#skewness and kurtosis\n",
        "print(\"Skewness after transformation: %f\" % np.sqrt(df['Rented Bike Count']).skew())\n",
        "print(\"Kurtosis after transformation: %f\" % np.sqrt(df['Rented Bike Count']).kurt())"
      ],
      "metadata": {
        "id": "ZZvvH5aCvxF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After root squaring the target variable,we are able to reduce the Skewness to 0.25 and Kurtosis to -0.64."
      ],
      "metadata": {
        "id": "ByVRW82dLMtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analysing the correlation between different numerical variables.*"
      ],
      "metadata": {
        "id": "JHu24VL4MEQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Relation Between Two Numerical Variables\n",
        "sns.pairplot(df,vars=['Rented Bike Count','Hour','Temperature(째C)','Humidity(%)','Wind speed (m/s)','Visibility (10m)',], hue='Seasons')\n"
      ],
      "metadata": {
        "id": "gWSXsLFezb6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*First we need to convert the Date columns from string to date time format for data processing.*"
      ],
      "metadata": {
        "id": "2i0Y4r3bWrTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#Convert the Date column in Datetime Dtype\n",
        "df['Date']=pd.to_datetime(df['Date'])\n",
        "\n",
        "#Breaking Down the Date into 3 Components\n",
        "df['Day']=df['Date'].dt.day\n",
        "df['Month']=df['Date'].dt.month\n",
        "df['Year']=df['Date'].dt.year"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Date'],axis=1,inplace=True) #Removing Date Column"
      ],
      "metadata": {
        "id": "Yhx5Iczq8ox6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().columns"
      ],
      "metadata": {
        "id": "xckhkB5G8YNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#Vizualizing Density of various features\n",
        "numerical_features=df.describe().columns\n",
        "for col in numerical_features[1:]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df[col]\n",
        "    sns.distplot(feature,bins=50, ax = ax,color='y')\n",
        "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)    \n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*By analyzing the density plot of different numerical features,it can be concluded tha*t-\n",
        "\n",
        "Feature with near normal distribution are-\n",
        "  \n",
        "    1-Temperature-(mean-13 degree celcius)\n",
        "\n",
        "    2-Humidity-(mean-58%)\n",
        "\n",
        "\n",
        "Feature with skewed distribution are-\n",
        "\n",
        "    1-Wind Speed-(Mean-1.62 m/s)\n",
        "   \n",
        "    2-Visibility-(Mean-1434 10m)\n",
        "\n",
        "    3-Solar Radiation-(Mean-0.5 MJ/m2)\n",
        "\n",
        "    4-Rainfall-(Mean-0.1 mm)\n",
        "\n",
        "    5-Snowfall-(Mean-0.064 cm)"
      ],
      "metadata": {
        "id": "ubnYqPCOXnmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analysing the relation of Number of Rented Bike with respect to different numerical features*."
      ],
      "metadata": {
        "id": "ac0xIygfeEXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#Visualizing Relation of Dependent Variable with numerical independent features\n",
        "for col in numerical_features[1:]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df[col]\n",
        "    label = df['Rented Bike Count']\n",
        "    correlation = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Rented Bike Count')\n",
        "    ax.set_title('Rented Bike Count vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(df[col], df['Rented Bike Count'], 1)\n",
        "    y_hat = np.poly1d(z)(df[col])\n",
        "\n",
        "    plt.plot(df[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion-\n",
        "\n",
        "    1-Most number of bikes rented in between 15 and 20 hrs which shows evening period sees higher demand.\n",
        "    2-Temperature having 20 to 30 degree celcius sees highest demand of rental bikes(Automn or Summer season).\n",
        "    3-Humidity with 40 to 70 % with maximum demand.\n",
        "    4-Lower wind speed increases the demand of Rental Bike.\n",
        "    5-Demand of rental bikes increased with higher visibility.\n",
        "    6-Higher dew point temperature with greater demand of Rental Bikes.\n",
        "    7-Demand decreases with higher Solar Radiations.\n",
        "    8-Demand decreases during higher Rainfall and Snowfall."
      ],
      "metadata": {
        "id": "6ugg5jszhDLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Processing and Feature Engineering**"
      ],
      "metadata": {
        "id": "K1UzJvVkm92_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Outliers\n",
        "df=df[df['Wind speed (m/s)']<=4]\n",
        "df=df[df['Visibility (10m)']>=100]\n",
        "df=df[df['Solar Radiation (MJ/m2)']<=3]\n",
        "df=df[df['Rainfall(mm)']<=10]\n",
        "df=df[df['Snowfall (cm)']<=4]"
      ],
      "metadata": {
        "id": "unKEvFdkfonq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyzing the relation between rental bike count and numerical features**"
      ],
      "metadata": {
        "id": "v8Y4fJT2oTbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#Vizualizing Relation between categorical features with Dependent Variables\n",
        "for col in numerical_features[1:-2]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df[col]\n",
        "    label = df['Rented Bike Count']\n",
        "    correlation = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Rented Bike Count')\n",
        "    ax.set_title('Rented Bike Count vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(df[col], df['Rented Bike Count'], 1)\n",
        "    y_hat = np.poly1d(z)(df[col])\n",
        "\n",
        "    plt.plot(df[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TSAWjSlbzcdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysing Categorical features**"
      ],
      "metadata": {
        "id": "jF3VO5TDwU7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Seasons'].value_counts()"
      ],
      "metadata": {
        "id": "oB9K2sy2_Opu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that rental bikes are available evenly in different seasons."
      ],
      "metadata": {
        "id": "KduTE7Zvx6tD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#ploting Number of Rented bike in different Seasons\n",
        "bike_rented_per_season=df.groupby(['Seasons'])['Rented Bike Count'].mean()\n",
        "plt.rcParams['figure.figsize']=(7,7)\n",
        "sns.barplot(y=bike_rented_per_season,x=bike_rented_per_season.index,data=df)\n",
        "plt.ticklabel_format(style='plain', axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that demand of Rental Bikes are higher in Automn and Summer Season with average 800 and 1050 respectively while the Winter seen the list minimum demand of nearly 200."
      ],
      "metadata": {
        "id": "C8mjf644xBoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Holiday'].value_counts()"
      ],
      "metadata": {
        "id": "rWN1DA5N_3ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here data show the clearly working days are much more than Holidays."
      ],
      "metadata": {
        "id": "MYf2F3CsyMd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing Number of Rented Bike on the Basis of Holiday\n",
        "bike_rented_on_holiday=df.groupby(['Holiday'])['Rented Bike Count'].mean()\n",
        "plt.rcParams['figure.figsize']=(7,7)\n",
        "sns.barplot(y=bike_rented_on_holiday,x=bike_rented_on_holiday.index,data=df)\n",
        "plt.ticklabel_format(style='plain', axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F2WIlZ5taOOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the bar chart ,it can be clearly seen that demand of Rental bikes are more on working days."
      ],
      "metadata": {
        "id": "jltWotKHyvmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Functioning Day'].value_counts()"
      ],
      "metadata": {
        "id": "HDJPVF6UAA1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can be seen that Functioning Days are much more than the non functioning days."
      ],
      "metadata": {
        "id": "j3HYCw5rzJUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_rented_on_functioning_day=df.groupby(['Functioning Day'])['Rented Bike Count'].mean()\n",
        "plt.rcParams['figure.figsize']=(7,7)\n",
        "sns.barplot(y=bike_rented_on_functioning_day,x=bike_rented_on_functioning_day.index,data=df)\n",
        "plt.ticklabel_format(style='plain', axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GFuYTHzndijr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analysing the correlation among different variables.*"
      ],
      "metadata": {
        "id": "n86viaxl0dwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#Visualizing the correlation among different variable\n",
        "plt.figure(figsize=(15,8))\n",
        "cbar_kws = { \n",
        "            \"shrink\":1,\n",
        "            'extend':'min', \n",
        "            'extendfrac':0.1, \n",
        "            \"ticks\":np.arange(0,22), \n",
        "            \"drawedges\":True,\n",
        "           }\n",
        "correlation = df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm',linewidth=1,cbar_kws=cbar_kws)"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the heatmap it can be seen that-\n",
        "\n",
        "    1-Majority of the features are not correlated with each others.\n",
        "\n",
        "    2-Temperature has the highest correlation with Dew Point Temperatures.\n",
        "\n",
        "    3-While humidity is also highly correlated with visibility."
      ],
      "metadata": {
        "id": "IQcVsWaW2OX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying correlating variables with the help of variance inflation factor to get clear pictures.."
      ],
      "metadata": {
        "id": "P5EmCIFM3aRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Treating Correlating Variables\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(x):\n",
        "  vif=pd.DataFrame()\n",
        "  vif['variable']=x.columns\n",
        "  vif['vif']=[variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n",
        "  return (vif)"
      ],
      "metadata": {
        "id": "rr1biLMl1vsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count','Day','Month','Year']]])"
      ],
      "metadata": {
        "id": "-UekFGmW3heN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count','Day','Month','Year','Dew point temperature(째C)']]])"
      ],
      "metadata": {
        "id": "UEtBc8a3A6Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the Dew Point Temperature."
      ],
      "metadata": {
        "id": "Lx1inWmihXb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Dew point temperature(째C)'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "_RWjalr4Zb2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features=['Hour','Temperature(째C)','Humidity(%)','Wind speed (m/s)','Visibility (10m)','\tSolar Radiation (MJ/m2)','Rainfall(mm)','Snowfall (cm)']"
      ],
      "metadata": {
        "id": "Oi1fji9LES_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let see,the correlation between variables after its treatment."
      ],
      "metadata": {
        "id": "U3ZaBULL4nOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing Correlation after treatment\n",
        "plt.figure(figsize=(15,8))\n",
        "correlation = df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True)"
      ],
      "metadata": {
        "id": "JpuBSNNIYEgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features=df.describe(include=['object','category']).columns"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features"
      ],
      "metadata": {
        "id": "XMW7hUUgfeER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analysing the number of rented bike with respect to the different categorical features.*"
      ],
      "metadata": {
        "id": "G77D7uB6dnwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all we ll plot the boxplot and analyse the density as well as outliers."
      ],
      "metadata": {
        "id": "EYd191PdeOgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing outlier through Boxplot\n",
        "for col in categorical_features:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    df.boxplot(column = 'Rented Bike Count', by = col, ax = ax)\n",
        "    ax.set_title('Label by ' + col)\n",
        "    ax.set_ylabel(\"Rented Bike Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hk4Ufw9PHGeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After vizualisation we can conclude that-\n",
        "\n",
        "    1-Maximum demand density of rental bike is in Automn and Summer.\n",
        "    2-Above features have higher density of outliers,thus removing them could cause the major data lost."
      ],
      "metadata": {
        "id": "oV93sl1de4Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Encoding the Categorical Data*"
      ],
      "metadata": {
        "id": "u4llj-pJlFct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding ll help to process the categorical data by assigning them a numerical values."
      ],
      "metadata": {
        "id": "N9B8KvMCl_jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding the categorical variables\n",
        "df_pr=df.copy()\n",
        "def encoder(data,columns):\n",
        "  data=pd.concat([data,pd.get_dummies(data[columns],prefix=columns,drop_first=True)],axis=1)\n",
        "  data=data.drop([columns],axis=1)\n",
        "  return data\n",
        "\n",
        "for col in categorical_features:\n",
        "  df_pr=encoder(df_pr,col)\n",
        "df_pr.head()"
      ],
      "metadata": {
        "id": "3J3HgbtCXGcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pr.drop(['Day','Year'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "1KE5qSQngKsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pr.head()"
      ],
      "metadata": {
        "id": "8InoDXtIgnhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we ll apply various the Models like-Linear Regression,Random Forest Regression and Polynomial Regression and then after evaluate the results."
      ],
      "metadata": {
        "id": "N2e64ZjEmY81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Assigning and Splitting the data for training and testing:*"
      ],
      "metadata": {
        "id": "3Xe7wj1ooxn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML Model - 1 Implementation\n",
        "x=df_pr.iloc[:,1:]\n",
        "y=np.sqrt(df_pr.iloc[:,:1])\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=0)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "JyAvWolHo5ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Scaling the data*"
      ],
      "metadata": {
        "id": "eCDne3JErIE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It help out to get rid of impact of the difference in magnitude of the different features."
      ],
      "metadata": {
        "id": "BTVZz_XIrTnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()\n",
        "x_train=scaler.fit_transform(x_train)\n",
        "x_test=scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "COop9I4Ro9kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "N3EIsEIOpWuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Implementation*"
      ],
      "metadata": {
        "id": "yp_xO9kXrlat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementation\n",
        "reg=LinearRegression().fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Model features*"
      ],
      "metadata": {
        "id": "GNiZPenirwUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg.score(x_train,y_train) "
      ],
      "metadata": {
        "id": "mDXYP9gt-B95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "IDSM-ORM-mRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_ #coefficient of parameter"
      ],
      "metadata": {
        "id": "x7X2dXAa-65t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prediction using the model*"
      ],
      "metadata": {
        "id": "DUp9Cp56r4vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "y_train_pred=reg.predict(x_train)\n",
        "y_test_pred=reg.predict(x_test)"
      ],
      "metadata": {
        "id": "0lpPfdS3_MJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*It's performance using Evaluation metric Score Chart.*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Train Data*"
      ],
      "metadata": {
        "id": "4Io2eEK7ITLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "#calculate MSE\n",
        "MSE_lr= mean_squared_error((y_train)**2, (y_train_pred)**2)\n",
        "print(\"MSE :\",MSE_lr)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print(\"RMSE :\",RMSE_lr)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_lr= mean_absolute_error(y_train**2, y_train_pred**2)\n",
        "print(\"MAE :\",MAE_lr)\n",
        "\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr= r2_score(y_train**2, y_train_pred**2)\n",
        "print(\"R2_Score :\",r2_lr)\n",
        "Adjusted_R2_lr = 1-(1-r2_score((y_train)**2, (y_train_pred)**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print(\"Adjusted R2 :\", Adjusted_R2_lr)"
      ],
      "metadata": {
        "id": "cKGb9XjVoL2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the R2_Score is quite low nearly 59% on train data ."
      ],
      "metadata": {
        "id": "U-0N5_rdH0a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Linear regression ',\n",
        "       'MAE':round((MAE_lr),3),\n",
        "       'MSE':round((MSE_lr),3),\n",
        "       'RMSE':round((RMSE_lr),3),\n",
        "       'R2_score':round((r2_lr),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_lr ),2)\n",
        "       }\n",
        "training_df=pd.DataFrame(dict1,index=[1])"
      ],
      "metadata": {
        "id": "32DnvETHpYnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Test Data*"
      ],
      "metadata": {
        "id": "GeCT_ZqaIdvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_lr=mean_squared_error(((y_test)**2),((y_test_pred)**2)) \n",
        "print('MSE',MSE_lr)\n",
        "\n",
        "MAE_lr=mean_absolute_error(((y_test)**2),((y_test_pred)**2))\n",
        "print('MAE',MAE_lr)\n",
        "\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print('RMSE',RMSE_lr)\n",
        "\n",
        "r2_lr=r2_score(((y_test)**2),((y_test_pred)**2))\n",
        "print('R2',r2_lr)\n",
        "Adjusted_R2_lr = 1-(1-r2_score(((y_test)**2), ((y_test_pred)**2)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print(\"Adjusted R2 : \",Adjusted_R2_lr)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here R2_Score is nearly 61% which is very less and generally not acceptable and need further tuning and transformation."
      ],
      "metadata": {
        "id": "2lLLx6lMseGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Linear regression ',\n",
        "       'MAE':round((MAE_lr),3),\n",
        "       'MSE':round((MSE_lr),3),\n",
        "       'RMSE':round((RMSE_lr),3),\n",
        "       'R2_score':round((r2_lr),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_lr ),2)\n",
        "       }\n",
        "test_df=pd.DataFrame(dict2,index=[1])"
      ],
      "metadata": {
        "id": "gBtKtNQesXWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualization*"
      ],
      "metadata": {
        "id": "mNpxh3_OIykb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the relation between the predicted value and actual values.\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter((y_test**2),((y_test_pred)**2),color='brown')\n",
        "plt.xlabel('True_Values')\n",
        "plt.ylabel('Predicted_Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ojl1iBMQHcKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above scatter plot,we can see that higher values giving more sparse values pointing toward the higher error.\n",
        "\n",
        "It shows that model is working well for lower values."
      ],
      "metadata": {
        "id": "cyDcZBqMu8dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error=((y_test)**2)-((y_test_pred)**2)"
      ],
      "metadata": {
        "id": "qqVpRI63JHa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(error)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YvYAmxQcJTIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above density plot shows the normal distribution of the error,which shows majority of the prediction are having low error."
      ],
      "metadata": {
        "id": "BgOq1xMTvhIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross- Validation & Hyperparameter Tuning\n",
        "\n"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we ll try to penalise the coffiecient parameters to reduce the error.\n",
        "\n",
        "Here we ll use three method that are Lasso Regression,Ridge Regression and Elastic Regression and Cross validate them"
      ],
      "metadata": {
        "id": "gsRDpyW_wK5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Lasso Regression*"
      ],
      "metadata": {
        "id": "Wm8qcwAb6UVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning using Lasso Regression\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso=Lasso(alpha=0.0001,max_iter=8000)\n",
        "lasso.fit(x_train,y_train) #fitting model"
      ],
      "metadata": {
        "id": "IGidvJhPRk7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(x_train,y_train)"
      ],
      "metadata": {
        "id": "clMzSpamSQ9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.coef_"
      ],
      "metadata": {
        "id": "AvAjSxIjTY3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Cross Validation*"
      ],
      "metadata": {
        "id": "7xJ_-cdI6aZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "#Implementing Cross Validation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "lasso=Lasso()\n",
        "parameters={'alpha':[1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]}\n",
        "lasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_regressor.fit(x_train,y_train) #Fitting the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Best Lasso Parameter*"
      ],
      "metadata": {
        "id": "50nENTh__EU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing optimal parameter\n",
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "8nC3xtvVamM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Fitting the model with best parameter of lasso*"
      ],
      "metadata": {
        "id": "LZu0diW8_H7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "las=Lasso(alpha=0.001,max_iter=3000)\n",
        "las.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "uRhbdymb4arP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prediction using Lasso Model*"
      ],
      "metadata": {
        "id": "QYfg8GTkJT5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting through model\n",
        "y_pred_train_lasso=las.predict(x_train) # Prediction on test data\n",
        "y_pred_test_lasso=las.predict(x_test) # Prediction on test data"
      ],
      "metadata": {
        "id": "9g8hevdWeJo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analysing ERROR*\n",
        "\n"
      ],
      "metadata": {
        "id": "tdAnOnH6_gFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Lasso Model on Train Data*"
      ],
      "metadata": {
        "id": "SA6fS5dEAJpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_l= mean_squared_error((y_train)**2, (y_pred_train_lasso)**2)\n",
        "print(\"MSE :\",MSE_l)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l=np.sqrt(MSE_l)\n",
        "print(\"RMSE :\",RMSE_l)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l= mean_absolute_error(y_train**2, y_pred_train_lasso**2)\n",
        "print(\"MAE :\",MAE_l)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l= r2_score(y_train**2, y_pred_train_lasso**2)\n",
        "print(\"R2_Score :\",r2_l)\n",
        "Adjusted_R2_l = (1-(1-r2_score(y_train**2, y_pred_train_lasso**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train**2, y_pred_train_lasso**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "79SVqjhP2ods"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here also R2_Score is similar to Linear Regression thus not having any major impact of penalization of parameter using Lasso."
      ],
      "metadata": {
        "id": "y3FuD6oaKej2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Lasso regression ',\n",
        "       'MAE':round((MAE_l),3),\n",
        "       'MSE':round((MSE_l),3),\n",
        "       'RMSE':round((RMSE_l),3),\n",
        "       'R2_score':round((r2_l),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_l ),2)\n",
        "       }\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "TRu85KGdaaBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Lasso Model on Test Data*"
      ],
      "metadata": {
        "id": "MRQAbwV_LeyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation of Lasso Model\n",
        "\n",
        "MSE_l= mean_squared_error(((y_test)**2), (y_pred_test_lasso)**2)\n",
        "print(\"MSE :\" , MSE_l)\n",
        "\n",
        "RMSE_l = np.sqrt(MSE_l)\n",
        "print(\"RMSE :\" ,RMSE_l)\n",
        "\n",
        "MAE_l=mean_absolute_error(((y_test)**2), ((y_pred_test_lasso)**2))\n",
        "print(\"MAE :\",MAE_l)\n",
        "\n",
        "r2_l= r2_score(((y_test)**2), (y_pred_test_lasso)**2)\n",
        "print(\"R2 :\" ,r2_l)\n",
        "Ajusted_R2_l=1-(1-r2_score(((y_test)**2), (y_pred_test_lasso)**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print(\"Adjusted R2 : \",Ajusted_R2_l)"
      ],
      "metadata": {
        "id": "w0tyW-1BgSH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the slight increase in R2_Score to 60% on test data which shows that model is not working well."
      ],
      "metadata": {
        "id": "ySx59AHlAZtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Lasso regression ',\n",
        "       'MAE':round((MAE_l),3),\n",
        "       'MSE':round((MSE_l),3),\n",
        "       'RMSE':round((RMSE_l),3),\n",
        "       'R2_score':round((r2_l),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_l ),2),\n",
        "       }\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "Ywsc7rCGakZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualization*"
      ],
      "metadata": {
        "id": "zz4jaPRcWVBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the accuracy of Predicted value with True Value\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter((y_pred_test_lasso)**2,(y_test)**2)\n",
        "plt.xlabel('True_Values')\n",
        "plt.ylabel('Lasso_predicted_Value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eOwH8nyyJyWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After visualizing the above ScatterPlot ,we can see increase in linearity of the relationship between True Values and Predicted Values which shows the reduction in error compared to simple Linear Regression Model."
      ],
      "metadata": {
        "id": "dFAmtREHJwQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Regression**"
      ],
      "metadata": {
        "id": "NKzTAB9GBOBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter tuning using Ridge Regression\n",
        "from sklearn.linear_model import Ridge\n",
        "parameters={'alpha' : [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100,0.1]}\n",
        "ridge_regressor=GridSearchCV(Ridge(),parameters,scoring='neg_mean_squared_error',cv=3)\n",
        "ridge_regressor.fit(x_train,y_train) #Fitting the model"
      ],
      "metadata": {
        "id": "4oP0EWYGkuOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Best Parameter on Ridge Regression*"
      ],
      "metadata": {
        "id": "XrV6aKEPBVAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing the optimal parameters\n",
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "pUPEnYLjnKb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prediction using Ridge Regression*"
      ],
      "metadata": {
        "id": "3kl-HRHMBadF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction using Ridge Regression\n",
        "y_pred_train_ridge=ridge_regressor.predict(x_train) #prediction on training data\n",
        "y_pred_test_ridge=ridge_regressor.predict(x_test) #Prediction on test data"
      ],
      "metadata": {
        "id": "JIzu4iGjpniB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Ridge Regression on Train Data*"
      ],
      "metadata": {
        "id": "XiYAulpcBf58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation of model(Ridge)\n",
        "MSE_r  = mean_squared_error((y_train)**2, (y_pred_train_ridge)**2)\n",
        "print(\"MSE :\" , MSE_r)\n",
        "\n",
        "RMSE_r = np.sqrt(MSE_r)\n",
        "print(\"RMSE :\" ,RMSE_r)\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r= mean_absolute_error(y_train**2, y_pred_train_ridge**2)\n",
        "print(\"MAE :\",MAE_r)\n",
        "\n",
        "r2_r = r2_score((y_train)**2, (y_pred_train_ridge)**2)\n",
        "print(\"R2 :\" ,r2_r)\n",
        "Adjusted_R2_r = 1-(1-r2_score((y_train)**2, (y_pred_train_ridge)**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train)**2, (y_pred_train_ridge)**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "Y3jo6ZlVrAyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On train data,the R2_Score is nearly 58% which shows that just like lasso ,ridge also not able to put major impact on accuracy."
      ],
      "metadata": {
        "id": "somlL-4rDCPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Ridge regression ',\n",
        "       'MAE':round((MAE_r),3),\n",
        "       'MSE':round((MSE_r),3),\n",
        "       'RMSE':round((RMSE_r),3),\n",
        "       'R2_score':round((r2_r),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_r ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "Jkqb8vsAnUhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating model\n",
        "MAE_r  = mean_absolute_error(((y_test)**2), (y_pred_test_ridge)**2)\n",
        "print(\"MSE :\" , MAE_r)\n",
        "\n",
        "MSE_r  = mean_squared_error(((y_test)**2), (y_pred_test_ridge)**2)\n",
        "print(\"MSE :\" , MSE_r)\n",
        "\n",
        "\n",
        "RMSE_r = np.sqrt(MSE_r)\n",
        "print(\"RMSE :\" ,RMSE_r)\n",
        "\n",
        "r2_r= r2_score(((y_test)**2),(y_pred_test_ridge)**2)\n",
        "print(\"R2 :\" ,r2_r)\n",
        "Adjusted_R2_r= 1-(1-r2_score((y_test),(y_pred_test_ridge)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test),(y_pred_test_ridge)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "_3tUhi1inVTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On test data,here the R2_Score on test is nearly 60% lesser than Lasso Regression."
      ],
      "metadata": {
        "id": "nqZ_vDrtD1FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Ridge regression ',\n",
        "       'MAE':round((MAE_r),3),\n",
        "       'MSE':round((MSE_r),3),\n",
        "       'RMSE':round((RMSE_r),3),\n",
        "       'R2_score':round((r2_r),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_r ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "pnY6Zex7mUSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualization*"
      ],
      "metadata": {
        "id": "vL2XsmHVY9IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the accuracy of Predicted value with True Value\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter((y_test),np.array(y_pred_test_ridge))\n",
        "plt.xlabel('True_Values')\n",
        "plt.ylabel('Ridge_predicted_Value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e2OMoDc1pl0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see from the above Scatter plot is decrease in density compared to the Lasso Regression which point toward the decrease in Accuracy."
      ],
      "metadata": {
        "id": "xHE8NphjEPj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ElasticNet**"
      ],
      "metadata": {
        "id": "ZADiJorZEoGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HyperparameterTuning using ElasticNet\n",
        "from sklearn.linear_model import ElasticNet\n",
        "#a * L1 + b * L2\n",
        "#alpha = a + b and l1_ratio = a / (a + b)\n",
        "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)"
      ],
      "metadata": {
        "id": "FX__r5advzSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet.fit(x_train,(y_train)) #Fitting the model"
      ],
      "metadata": {
        "id": "WBjdp5iQv7IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet.score(x_train, (y_train)) #Evaluating the model"
      ],
      "metadata": {
        "id": "M4AD2T23wBv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prediction using Elasticnet*"
      ],
      "metadata": {
        "id": "_PbuxuFEZJkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_en=elasticnet.predict(x_train)\n",
        "y_pred_test_en=elasticnet.predict(x_test)"
      ],
      "metadata": {
        "id": "ZiFtSgthm4lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of Elastic Net on Train Data"
      ],
      "metadata": {
        "id": "JlnpL3ksZcGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e= mean_squared_error((y_train)**2, (y_pred_train_en)**2)\n",
        "print(\"MSE :\",MSE_e)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e=np.sqrt(MSE_e)\n",
        "print(\"RMSE :\",RMSE_e)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e= mean_absolute_error(y_train, y_pred_train_en)\n",
        "print(\"MAE :\",MAE_e)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e= r2_score(y_train**2, y_pred_train_en**2)\n",
        "print(\"R2 :\",r2_e)\n",
        "Adjusted_R2_e=(1-(1-r2_score(y_train**2, y_pred_train_en**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train**2, y_pred_train_en**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "KQd3U4cCoHKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that R2_Score even dipped to 42% which is totally unacceptable."
      ],
      "metadata": {
        "id": "wSF6GZIAaY5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Elastic net regression ',\n",
        "       'MAE':round((MAE_e),3),\n",
        "       'MSE':round((MSE_e),3),\n",
        "       'RMSE':round((RMSE_e),3),\n",
        "       'R2_score':round((r2_e),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_e ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "2yUj_-gkpEFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Elastic Net on Test Data*"
      ],
      "metadata": {
        "id": "LJPrmWaGaqLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e= mean_squared_error(y_test**2, y_pred_test_en**2)\n",
        "print(\"MSE :\",MSE_e)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e=np.sqrt(MSE_e)\n",
        "print(\"RMSE :\",RMSE_e)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e= mean_absolute_error(y_test**2, y_pred_test_en**2)\n",
        "print(\"MAE :\",MAE_e)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e= r2_score((y_test)**2, (y_pred_test_en)**2)\n",
        "print(\"R2 :\",r2_e)\n",
        "Adjusted_R2_e=(1-(1-r2_score((y_test)**2, (y_pred_test_en)**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test)**2, (y_pred_test_en)**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "zIdVKvwUpJ5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here in test data,R2_Score increased which shows that the model is not working properly on this dataset."
      ],
      "metadata": {
        "id": "NjHN_P3bduUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Elastic net regression Test',\n",
        "       'MAE':round((MAE_e),3),\n",
        "       'MSE':round((MSE_e),3),\n",
        "       'RMSE':round((RMSE_e),3),\n",
        "       'R2_score':round((r2_e),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_e ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "hLib_Db2p3mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Implementation of Random Forest Regressor*"
      ],
      "metadata": {
        "id": "eNhc86zvGIBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation the model\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor() #Initializing the model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = {'n_estimators':[50,80,100],'max_depth':[3,5,7]}, cv = 3, n_jobs = -1, verbose = 2)\n",
        "grid_search.fit(x_train,y_train) #fitting the model"
      ],
      "metadata": {
        "id": "svaV5og3ziFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prediction using Random Forest Regressor*"
      ],
      "metadata": {
        "id": "OedhggdXGPTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting for both train and test\n",
        "y_pred_train_r=grid_search.predict(x_train) #Prediction with Train Data\n",
        "y_pred_test_r=grid_search.predict(x_test)  #Prediction with Test Data\n"
      ],
      "metadata": {
        "id": "qgBOpXzyCPhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Random Forest Regressor on Train Data*"
      ],
      "metadata": {
        "id": "QdNL6PR5Gev2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",grid_search.score(x_train,y_train))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_rf= mean_squared_error(y_train**2, y_pred_train_r**2)\n",
        "print(\"MSE :\",MSE_rf)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_rf=np.sqrt(MSE_rf)\n",
        "print(\"RMSE :\",RMSE_rf)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_rf= mean_absolute_error(y_train**2, y_pred_train_r**2)\n",
        "print(\"MAE :\",MAE_rf)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_rf= r2_score(y_train**2, y_pred_train_r**2)\n",
        "print(\"R2 :\",r2_rf)\n",
        "Adjusted_R2_rf=(1-(1-r2_score(y_train**2, y_pred_train_r**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train**2, y_pred_train_r**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "HyBd9wolteCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the drastic increase of R2_Score to 83% which is very much acceptable."
      ],
      "metadata": {
        "id": "iCWoU1qpfv6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualization*"
      ],
      "metadata": {
        "id": "HYyQ7Ttugx5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the accuracy of predicted train data with respect to actual train data\n",
        "plt.scatter(y_train,y_pred_train_r)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')"
      ],
      "metadata": {
        "id": "sWsz5wE_gv6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Random forest regression ',\n",
        "       'MAE':round((MAE_rf),3),\n",
        "       'MSE':round((MSE_rf),3),\n",
        "       'RMSE':round((RMSE_rf),3),\n",
        "       'R2_score':round((r2_rf),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_rf ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "WQnkprNhw-s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Random Forest Regressor on Test Data*"
      ],
      "metadata": {
        "id": "F0uAbAndgQ_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_rf= mean_squared_error(y_test**2, y_pred_test_r**2)\n",
        "print(\"MSE :\",MSE_rf)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_rf=np.sqrt(MSE_rf)\n",
        "print(\"RMSE :\",RMSE_rf)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_rf= mean_absolute_error(y_test**2, y_pred_test_r**2)\n",
        "print(\"MAE :\",MAE_rf)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_rf= r2_score((y_test)**2, (y_pred_test_r)**2)\n",
        "print(\"R2 :\",r2_rf)\n",
        "Adjusted_R2_rf=(1-(1-r2_score((y_test)**2, (y_pred_test_r)**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test)**2, (y_pred_test_r)**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "LjuL8cEIC1K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are getting best good result with R2_Score 80% on test data,much better than the Lasso,Linear Regression"
      ],
      "metadata": {
        "id": "t7CRXpIWGpEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Random forest regression ',\n",
        "       'MAE':round((MAE_rf),3),\n",
        "       'MSE':round((MSE_rf),3),\n",
        "       'RMSE':round((RMSE_rf),3),\n",
        "       'R2_score':round((r2_rf),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_rf ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "sMY7z7X6xlUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score"
      ],
      "metadata": {
        "id": "fib-5d6sLOPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualization*"
      ],
      "metadata": {
        "id": "fMelHPRQg5zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the accuracy of predicted test data with respect to actual test data\n",
        "plt.scatter(y_test,y_pred_test_r)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')"
      ],
      "metadata": {
        "id": "FzhwN_VfQxiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the scatter plot,we can see the linearity of the relationship between Predicted Values and Actual Values which shows high accuracy and increase in variance with respect to testing data."
      ],
      "metadata": {
        "id": "xlOb7MlyITOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid Search CV**"
      ],
      "metadata": {
        "id": "mD1jv6iPJMZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross Validation And Hyperparameter Tuning\n",
        "from sklearn.model_selection import GridSearchCV "
      ],
      "metadata": {
        "id": "jqUzpE58YA2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'criterion':['squared_error', 'absolute_error', 'poisson'],'max_features':['auto', 'sqrt', 'log2']}"
      ],
      "metadata": {
        "id": "oHfVV2niVLgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing the grid search using the parameters with cv of 5\n",
        "grid = GridSearchCV(rf,parameters,cv=5,scoring='neg_mean_squared_error')\n",
        "#Fitting it on our training dataset\n",
        "grid.fit(x_train,y_train) #fitting the model"
      ],
      "metadata": {
        "id": "lq3UD4hMUVJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Optimal Parameters*"
      ],
      "metadata": {
        "id": "f3M0yU-UK_Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_ #Optimal Parameter"
      ],
      "metadata": {
        "id": "TORrasW_YY6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_cv=RandomForestRegressor(n_estimators=100,random_state=0,criterion='squared_error',max_features='auto',max_depth=15) #Initializing Tuned optimal model"
      ],
      "metadata": {
        "id": "i6-RZ_DXcYnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_cv.fit(x_train,y_train) #fitting the model"
      ],
      "metadata": {
        "id": "NpeEJWE4fIAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prediction on Model*"
      ],
      "metadata": {
        "id": "9DJ8S7sPLEij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_cv=gs_cv.predict(x_train) #Prediction on Train Data"
      ],
      "metadata": {
        "id": "tum_EMNIfeu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test_cv=gs_cv.predict(x_test) #Prediction on Test Data"
      ],
      "metadata": {
        "id": "DlRRsX2ylCs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation Grid Search on Train Data*"
      ],
      "metadata": {
        "id": "wZyrGEquLL-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",gs_cv.score(x_train,y_train))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_cv= mean_squared_error(y_train**2, y_pred_train_cv**2)\n",
        "print(\"MSE :\",MSE_cv)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_cv=np.sqrt(MSE_cv)\n",
        "print(\"RMSE :\",RMSE_cv)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_cv= mean_absolute_error(y_train**2, y_pred_train_cv**2)\n",
        "print(\"MAE :\",MAE_cv)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_cv= r2_score(y_train**2, y_pred_train_cv**2)\n",
        "print(\"R2 :\",r2_cv)\n",
        "Adjusted_R2_cv=(1-(1-r2_score(y_train**2, y_pred_train_cv**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train**2, y_pred_train_cv**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n"
      ],
      "metadata": {
        "id": "RiX55tXnlqpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gave the best result with R2_Score 97% on train data which is tending toward the overfitting."
      ],
      "metadata": {
        "id": "pNPkcsheLQUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Random forest Regression-Cross Validation ',\n",
        "       'MAE':round((MAE_cv),3),\n",
        "       'MSE':round((MSE_cv),3),\n",
        "       'RMSE':round((RMSE_cv),3),\n",
        "       'R2_score':round((r2_cv),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_cv ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "8GL9rXvADwjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualization*"
      ],
      "metadata": {
        "id": "W37ZvNFirRRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the accuracy of predicted train value with respect to actual train value\n",
        "plt.scatter(y_train,y_pred_train_cv,color='g')\n",
        "plt.xlabel('Actual Value')\n",
        "plt.ylabel('Predicted Value')"
      ],
      "metadata": {
        "id": "u9SpKj1NpHwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very high linearity and low variance looking like it overfit on train data."
      ],
      "metadata": {
        "id": "qXDV3yQvu0uI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of GridSearchCV on Test Data*"
      ],
      "metadata": {
        "id": "LgvPt6UZrYJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",gs_cv.score(x_test,y_test))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_cv= mean_squared_error(y_test**2, y_pred_test_cv**2)\n",
        "print(\"MSE :\",MSE_cv)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_cv=np.sqrt(MSE_cv)\n",
        "print(\"RMSE :\",RMSE_cv)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_cv= mean_absolute_error(y_test**2, y_pred_test_cv**2)\n",
        "print(\"MAE :\",MAE_cv)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_cv= r2_score(y_test**2, y_pred_test_cv**2)\n",
        "print(\"R2_Score:\",r2_cv)\n",
        "Adjusted_R2_cv=(1-(1-r2_score(y_test**2, y_pred_test_cv**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_test**2, y_pred_test_cv**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "SUzI8G8o-Z5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here on Test Data,this model is giving the best result of R2_Score nearly 87% which makes it most suitable model to implement."
      ],
      "metadata": {
        "id": "87CW37Jtrpa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Random forest regression-Cross Validation ',\n",
        "       'MAE':round((MAE_cv),3),\n",
        "       'MSE':round((MSE_cv),3),\n",
        "       'RMSE':round((RMSE_cv),3),\n",
        "       'R2_score':round((r2_cv),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_cv ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "oydCGN9KEbL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualization*"
      ],
      "metadata": {
        "id": "vQo-gj0OsJHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the accuracy of predicted test value with respect to actual test value\n",
        "plt.scatter(y_test,y_pred_test_cv,color='g')\n",
        "plt.xlabel('Actual Value')\n",
        "plt.ylabel('Predicted Value')"
      ],
      "metadata": {
        "id": "_vaCGycoppZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above scatter plot shows the increase in linearity and variance with a high accuracy of predicted values with respect to actual values."
      ],
      "metadata": {
        "id": "A0cIQPBZTLSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Polynomial Regression**"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Implementation*"
      ],
      "metadata": {
        "id": "CLYRnaJ5UN0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Defining the variables\n",
        "dependent_variable = 'Rented Bike Count'\n",
        "independent_variables = list(set(df_pr.columns[1:].tolist()) - {dependent_variable})\n",
        "\n",
        "x=df_pr.iloc[:,1:]\n",
        "y=np.sqrt(df_pr.iloc[:,:1])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
        "poly_features = PolynomialFeatures(degree=2) #Initializing the model\n",
        "x_train_poly = poly_features.fit_transform(x_train)\n",
        "poly_model = LinearRegression() \n",
        "poly_model.fit(x_train_poly, y_train) #fitting the model\n",
        "y_pred_train_p = poly_model.predict(x_train_poly) #Predicting the model on train data\n",
        "y_pred_test_p = poly_model.predict(poly_features.fit_transform(x_test)) #Predicting the model on test data"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Polynomial Regression*"
      ],
      "metadata": {
        "id": "V1iPvb9MUiTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",poly_model.score(x_train_poly,y_train))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_p= mean_squared_error(y_train**2, y_pred_train_p**2)\n",
        "print(\"MSE :\",MSE_rf)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_p=np.sqrt(MSE_p)\n",
        "print(\"RMSE :\",RMSE_p)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_p= mean_absolute_error(y_train**2, y_pred_train_p**2)\n",
        "print(\"MAE :\",MAE_p)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_p= r2_score(y_train**2, y_pred_train_p**2)\n",
        "print(\"R2 :\",r2_p)\n",
        "Adjusted_R2_p=(1-(1-r2_score(y_train**2, y_pred_train_p**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train**2, y_pred_train_p**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "m5Ce57QjanQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial Regression is also doing well in comparison to many model with the R2_Score 72% on Train Data."
      ],
      "metadata": {
        "id": "Bxf9sVaO0K6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Polynomial regression ',\n",
        "       'MAE':round((MAE_p),3),\n",
        "       'MSE':round((MSE_p),3),\n",
        "       'RMSE':round((RMSE_p),3),\n",
        "       'R2_score':round((r2_p),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_p ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "_y10JUXBLvsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualization*"
      ],
      "metadata": {
        "id": "_YPYh9aO0zKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vizualizing the predicted train data with respect to the actual train data\n",
        "plt.scatter(y_train,y_pred_train_p)\n",
        "plt.xlabel('Actual value'),plt.ylabel('Predicted value')\n",
        "plt.title('Training Error')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LxNxQJseXfrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "High variance with average bias is accepted model for this data set."
      ],
      "metadata": {
        "id": "l7nKgCSD09DW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation of Polynomial Regression on Test Data*"
      ],
      "metadata": {
        "id": "yEjWY23O1UfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate MSE\n",
        "MSE_p= mean_squared_error(y_test**2, y_pred_test_p**2)\n",
        "print(\"MSE :\",MSE_p)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_p=np.sqrt(MSE_p)\n",
        "print(\"RMSE :\",RMSE_p)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_p= mean_absolute_error(y_test**2, y_pred_test_p**2)\n",
        "print(\"MAE :\",MAE_p)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_p= r2_score(y_test**2, y_pred_test_p**2)\n",
        "print(\"R2 :\",r2_p)\n",
        "Adjusted_R2_p=(1-(1-r2_score(y_test**2, y_pred_test_p**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_test**2, y_pred_test_p**2))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "RCwIy4mYM1MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Polynomial regression ',\n",
        "       'MAE':round((MAE_p),3),\n",
        "       'MSE':round((MSE_p),3),\n",
        "       'RMSE':round((RMSE_p),3),\n",
        "       'R2_score':round((r2_p),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_p ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "YqBKHRd8PTXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "id": "bPa3Dpd93ya2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vizualising the predicted test data with respect to the actual test data\n",
        "plt.scatter(y_test**2,y_pred_test_p**2)\n",
        "plt.xlabel('Actual value'),plt.ylabel('Predicted value')\n",
        "plt.title('Test Error')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qqyp_I4iZqJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above Scatter Plot we can visualize the accuracy of the Predicted Values with respect to Actual Values more scattered than train data shows bit high variance."
      ],
      "metadata": {
        "id": "XEKon2VuVbLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing error density\n",
        "error_poly=((y_test)**2)-((y_pred_test_p)**2)\n",
        "sns.distplot(error_poly)"
      ],
      "metadata": {
        "id": "M1BZTuPTaQgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Skewness: %f\" % error_poly.skew())\n",
        "print(\"Kurtosis: %f\" % error_poly.kurt())"
      ],
      "metadata": {
        "id": "EnSlM0LqWylD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that despite skewness is under acceptable range,its Kurtosis is quiet high."
      ],
      "metadata": {
        "id": "xfwzRPGFXE9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here Error density follows the normal distribution"
      ],
      "metadata": {
        "id": "HbXcgTTXWTTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison"
      ],
      "metadata": {
        "id": "yZHupLZ5ih02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*R2_Score*"
      ],
      "metadata": {
        "id": "05Ga70xQrlk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparison of different model with respect to following metrics\n",
        "#R2_SCORE\n",
        "model=['Linear Regression','Lasso Regression','Ridge Regression','Elastic Regression','Random Forest Regression','GridSearchCV','Polynomial Regression']\n",
        "acc=[r2_lr,r2_l,r2_r,r2_e,r2_rf,r2_cv,r2_p]\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x=model,y=acc)\n",
        "plt.xlabel('Model')\n",
        "plt.xticks(rotation=30)\n",
        "ax.XTickLabelRotation = 45;\n",
        "plt.ylabel('R2_SCORE')\n"
      ],
      "metadata": {
        "id": "KpZkUIJUTzsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above Barplot we can visualize that Tuned Random forest Regression Model gives the least Mean Squarred Error with less than 60000 while Linear Regression Model gives the Maximum Mean Squared Error with more than 140000."
      ],
      "metadata": {
        "id": "BSz-F1fMYMru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Mean Squared Data*"
      ],
      "metadata": {
        "id": "ct8DL2NOrzkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparison of different model with respect to following metrics\n",
        "#MEAN SQUARE ERROR\n",
        "model=['Linear Regression','Lasso Regression','Ridge Regression','Elastic Regression','Random Forest Regression','GridSearch CV','Polynomial Regression']\n",
        "acc=[MSE_lr,MSE_l,MSE_r,MSE_e,MSE_rf,MSE_cv,MSE_p]\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x=model,y=acc)\n",
        "plt.xlabel('Model')\n",
        "plt.xticks(rotation=30)\n",
        "ax.XTickLabelRotation = 45;\n",
        "plt.ylabel('MEAN SQUARE ERROR')\n"
      ],
      "metadata": {
        "id": "DuneIy2yT2i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we compare the R2_Score of the different models,we can see that the GridSearchCV gives the maximum accuracy with more than 85% while Elastic Net gives minimum accuracy with less than 50%."
      ],
      "metadata": {
        "id": "Q49-RDoyZCEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comparison of Models on different evaluation metrics*"
      ],
      "metadata": {
        "id": "pTQju5Nh6mGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result=pd.concat([training_df,test_df],keys=['Training set','Test set'])\n",
        "result"
      ],
      "metadata": {
        "id": "XNXURrXZVj1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing importance of different features"
      ],
      "metadata": {
        "id": "vbcx37CoiqOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we take the best fit model the we have to choose here is Random Forest Model then after we ll try to find the importance of the features."
      ],
      "metadata": {
        "id": "fY7ItriNZ99M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid Search**"
      ],
      "metadata": {
        "id": "7ZPogoc-fXeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#feature importance in tuned random forest classifier\n",
        "rf_optimal_model=grid_search.best_estimator_\n",
        "rf_optimal_model"
      ],
      "metadata": {
        "id": "R9Cj_DgXJxQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_optimal_model.feature_importances_"
      ],
      "metadata": {
        "id": "3VMIUS9XKPFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances=rf_optimal_model.feature_importances_"
      ],
      "metadata": {
        "id": "wk8APL7BLCZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_dict = {'Feature' : list(x.columns),\n",
        "                   'Feature Importance' : importances}\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict)"
      ],
      "metadata": {
        "id": "VHZ94umGOQ3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"
      ],
      "metadata": {
        "id": "mOuncX5iOpa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df=importance_df.sort_values(by=['Feature Importance'],ascending=False)"
      ],
      "metadata": {
        "id": "rNP82vbYQtPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df.head(10).reset_index()"
      ],
      "metadata": {
        "id": "gFSYLGImPboq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# visualizing feature importance \n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title('Feature Importance')\n",
        "sns.barplot(x=importance_df['Feature Importance'],y=importance_df['Feature'],hue=importance_df['Feature'])"
      ],
      "metadata": {
        "id": "NdQwMwbpS4vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above bar chart we can see that the Temperature and Time(Hour) play the maximum role in affecting the demand of the Rental Bike."
      ],
      "metadata": {
        "id": "wxseQqoWatGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Explainabilty"
      ],
      "metadata": {
        "id": "jD-CGy6KjTw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Explaination of model using Eli5.*"
      ],
      "metadata": {
        "id": "J6Lj3Xb7elKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install eli5"
      ],
      "metadata": {
        "id": "5N3KmAS_UCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here,according to Eli5,Temperature and time have negative contribution  on demand with a higher values."
      ],
      "metadata": {
        "id": "aPOtGUD9fOyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "-9s6DXm2Zzdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the time of our analysis, we initially did EDA on all the features of our datset. We first analysed our dependent variable, 'Rented Bike Count' and also transformed it. Next we analysed categorical variable and dropped the variable who had majority of one class, we also analysed numerical variable, found out the correlation, distribution and their relationship with the dependent variable. We also removed some numerical features who had mostly 0 values and hot encoded the categorical variables.\n",
        "\n",
        "Next we implemented 6 machine learning algorithms Linear Regression,lasso,ridge,elasticnet,Random Forest and Polynomial Regression. We did hyperparameter tuning to improve our model performance. The results of our evaluation are:\n",
        "\n"
      ],
      "metadata": {
        "id": "BXDKDWatZyxO"
      }
    }
  ]
}